# Problem-solving strategies

## Iterative and recursive mathematical functions

### Recursive functions

Contents in this section refer to [Recursive Functions][01] entry in *Stanford Encyclopedia of Philosophy*

> The recursive functions, which form a class of computable functions, take their name from the process of “recurrence” or “recursion”. In its most general numerical form the process of recursion consists in defining the value of a function by using other values of the same function.

There are **five type** of recursion:

* Iteration
* Primitive recursion
* Primitive recursion with parameters
* Course-of-value recursion
* Double recursion

#### The initial functions

In order to get the whole recursive process started, a certain class of functions need to be singled out, whose values do not in turn depend of their values for smaller arguments. These are called the **initial functions**.

The class of the initial functions:

* The **successor** function **s**, which when given an argument *n* as an argument returns its immediate successor **s**(*n*);

* The **constant** function **z**, which returns 0 for any argument n: **z**(*n*)=0;

* The **projection** functions, one for each pair of integer *n* and *i* (with *i*<=n), where **p**<sub>*n,i*</sub>(k<sub>1</sub>,...,k<sub>*n*</sub>)=k<sub>*i*</sub>
    * For simplicity, we omit the first index on the projection functions, since these can be inferred from the number of argument places. Thus, we abbreviate **p**<sub>*n,i*</sub>(k<sub>1</sub>,...,k<sub>*n*</sub>) as **p**<sub>*i*</sub>(k<sub>1</sub>,...,k<sub>*n*</sub>)

It is immediate to obtain further functions by combining initial functions, by a process referred to as composition.

The operation of **composition** (or **substitution**), is formally defined as follows:

> If *g* is a function of *m* arguments, and each of *h<sub>1</sub>,...,h<sub>m</sub>* is a function of *n* arguments, then the function *f*

>> *f(x<sub>1</sub>,...,x<sub>n</sub>) = g(h<sub>1</sub>(x<sub>1</sub>,...,x<sub>n</sub>),...,h<sub>m</sub>(x<sub>1</sub>,...,x<sub>n</sub>))*

> is *definable by composition from g and h<sub>1</sub>,...,h<sub>m</sub>*. We write *f = [g ○ h<sub>1</sub>,...,h<sub>m</sub>]*, and in the simple case where *m=1* and *h<sub>1</sub>* is designated *h*, we write *f(x) = [g ○ h]\(x)*

#### Iteration

The simplest type of recursion occurs when a given function is iterated. 

> Technically, the *n*-th iteration of a function *f* is defined as follows:

>> *f<sup>(0)</sup>(x) = x*

>> *f<sup>(n+1)</sup>(x) = f(f<sup>(n)</sup>(x)).*

> The first clause is needed to obtain *f<sup>(1)</sup>(x) = f(x)* from the second clause. We also have *f<sup>(2)</sup>(x) = f(f(x)), etc.*

#### Primitive recursion

> **Primitive recursion** is a procedure that defines the value of a function at an argument *n* by using its value at the previous argument *n - 1*.

Iteration is obviously a special case of primitive recursion, on the number of iterations. And so is the predecessor function, defined by

![predecessor function][02]

It is not immediate that the predecessor function can be reduced to an iteration, and hence is representable in the λ-Calculus. It was Kleene [1935] who saw how to do this. 

Basically, *pd(n)* is the second component of the *n*-th iteration of the function on pairs defined as

*f((x, y)) = (x + 1, x)*,

started on (0, 0).

More generally, it is possible to prove that **any primitive recursion can be reduced to an iteration**. This implies that all primitive recursive functions are actually representable in the λ-Calculus, as proved by Kleene [1936].

It has been standard to define the primitive recursive function as precisely those obtained from the initial functions by means of composition and primitive recursion. We have already given the formal definition of composition. The second operation which forms new primitive recursive functions from initial primitive recursive function is called **primitive recursion** and is formally defined as follows:

> A function *f* is *definable by primitive recursion from g and h* if:

>> *f(x, 0) = g(x)*

>> *f(x, __s__(y)) = h(x, y, f(x, y))*

> We write *f* = PR[*g, h*] when *f* is definable by primitive recursion from g and h.

As a simple example of a function definable by primitive recursion, consider arithmetic addition. The function sum(x, y) can be defined as follows:

> sum(x, 0) = x

> sum(x, **s**(y)) = **s**(sum(x, y))

Let us convince ourselves that this shows sum to be definable by recursion. 

Note here that in the first clause, sum(x, 0) can be understood as identified with the unary projection function of *x*, namely **p**<sub>1</sub>(x). So the first clause in the definition of sum satisfies the first clause in the definition of *definable by primitive recursion*, by letting *f(x, 0)* by sum(x, 0) and letting *g(x)* be **p**<sub>1</sub>(x)

To see that the second clause of the definition of *definable by primitive recursion* is satisfied, note that the definiens can be understood as the function *h(x, y, f(x, y))*, where *h* is identified as the composition of the successor function and the projection function **p**<sub>3</sub>:

**s**(sum(x, y)) = [**s** ○ **p**<sub>3</sub>]\(x, y, sum(x, y))

Thus, the second clause of definition of sum(x, y) has the form required by the definition of *definable by primitive recursion*. Consequently, sum(x, y) is definable by recursion from the functions **p**<sub>1</sub>(x) and [**s** ○ **p**<sub>3</sub>].

In what follows, we shall replace our definition of sum(x, y) with a definition that uses infix notation and which uses the notation *x'* instead of **s**(x) to denote the successor of *x*:

> *x + 0 = x*

> *x + y' = (x + y)'*

Here is a series of examples of arithmetic functions which are primitive recursive.

##### Multiplication

> *x · 0 = 0*

> *x · y' = x + (x · y)*

##### Exponential

> *x<sup>0</sup> = 1*

> *x<sup>y'</sup> = (x · x<sup>y</sup>)*

##### Factorial

> *0! = 1*

> *y'! = y' · y!*

##### Predecessor

> *pred(0) = 0*

> *pred(y') = y*

##### Truncated subtraction

> *x ∸ 0 = x*

> *x ∸ y' = pred(x ∸ y)*

##### Minimum

> *min(x, y) = x ∸ (x ∸ y)*

#### Primitive recursion with parameters

When defining a function of many variables by primitive recursion, all variables except one are kept fixed. Primitive recursion with parameters relaxes this condition, and it allows substitution for these variables. Although apparently more general, this notion actually turns out to be reducible to the usual primitive recursion.

One ancient example of primitive recursion with parameters is the solution to the old problem know as the *Tower of Hanoi*.

The natural recursive solution is the following: to move n disks from needle A to needle C, first move n-1 disks from needle A to needle B, then move one disk from needle A to needle C, and then move n-1 disks from needle B to needle C. More concisely:

*move(n, A, C) = move(n - 1, A, B) & move(n - 1, B, C)*

Notice the use of *move(n - 1, A, B)* and *move(n - 1, B, C)*, as opposed to *move(n - 1, A, C)*, in the computation of *move(n, A, C)*, which makes this a primitive recursion with parameters (the value *move(1, A, C)* does not count, being constant).

#### Course-of-values recursion

When defining by primitive recursion a function at a given argument, only the value for the immediately preceding argument can be used. Course-of-values recursion relaxes this condition, and it allows the use of any number of values for previous arguments. Although apparently more general, this notion actually turns out to be reducible to the usual primitive recursion as well.

An early example of a course-of-values recursion was given by Leonardo da Pisa, also called Fibonacci. The definition of the *Fibonacci sequence* is as follows:

> *f(0) = 0*

> *f(1) = 1*

> *f(n + 2) = f(n) + f(n + 1)*

Notice the use of the two values *f(n)* and *f(n + 1)* in the definition of *f(n + 2)*, which makes this a course-of-values recursion.

#### Double recursion

Primitive recursion can be used to define functions of many variables, but only by keeping all but one of them fixed. Double recursion relaxes this condition, and it allows the recursion to happen on two variables instead of only one. Although apparently more general, this notion actually turns out to be reducible in many cases (but not all) to the usual primitive recursion.

### Iterated functions

According to the discussion above, we can know that iterated functions occur as a special case of recursive functions.

## Iterative and recursive traversal of data structures

* Linked list

* Binary tree

* Graph

## Divide-and-conquer strategies

[01]: http://plato.stanford.edu/entries/recursive-functions/
[02]: ../../../img/pred_func.png